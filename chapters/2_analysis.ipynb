{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What Is Algorithm Analysis?\n",
    "\n",
    "**Algorithm analysis** is concerned with comparing algorithms based upon the amount of *computing resources* that each algorithm uses. We want to be able to consider two algorithms and say that one is better than the other because it is more efficient in its use of those resources or perhaps because it simply uses fewer. \n",
    "There are two different ways to look at *computing resources*.\n",
    "\n",
    "One way is to consider the **amount of space or memory** an algorithm requires to solve the problem. \n",
    "As an alternative to space requirements, we can analyze and compare algorithms based on the **amount of time** they require to execute (“execution time” or “running time” of the algorithm)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big-O Notation\n",
    "\n",
    "When trying to characterize an algorithm’s efficiency in terms of execution time, *independent of any particular program or computer*, it is important to quantify the *number of operations or steps* that the algorithm will require (We can denote this by a function, call it T. For example, T(n)=1+n steps. The parameter n is often referred to as the “*size of the problem*”, and we can read this as “T(n) is the time it takes to solve a problem of size n, namely 1+n steps.”). If each of these steps is considered to be a *basic unit of computation*, then the execution time for an algorithm can be expressed as the number of steps required to solve the problem. Deciding on an appropriate **basic unit of computation** can be a complicated problem and will depend on how the algorithm is implemented.\n",
    "\n",
    "But it turns out that the exact number of operations is not as important as determining the most *dominant part* of the T(n) function. In other words, as the problem gets larger, some portion of the T(n) function tends to overpower the rest. This dominant term is what, in the end, is used for comparison. The **order of magnitude** function describes the part of T(n) that increases the fastest as the value of n increases. Order of magnitude is often called **Big-O** notation (for “order”) and written as O(f(n)). It provides a useful approximation to the actual number of steps in the computation. The function f(n) provides a simple representation of the dominant part of the original T(n).\n",
    "\n",
    "For example:\n",
    "\n",
    "```python\n",
    "a=5\n",
    "b=6\n",
    "c=10\n",
    "for i in range(n):\n",
    "   for j in range(n):\n",
    "      x = i * i\n",
    "      y = j * j\n",
    "      z = i * j\n",
    "for k in range(n):\n",
    "   w = a*k + 45\n",
    "   v = b*b\n",
    "d = 33\n",
    "```\n",
    "\n",
    "In this example the basic unit of a computation will be the assignment statement. Thus $T(n)=3+3n^{2}+2n+1=3n^{2}+2n+4$. As n gets larger, the $n^{2}$ term becomes the most important. In fact, when n is really large, the other two terms become insignificant in the role that they play in determining the final result. In addition, the coefficient 3 becomes insignificant as n gets large. We would say that the function T(n) has an order of magnitude $f(n)=n^{2}$, or simply that it is $O(n^{2})$.\n",
    "\n",
    "Here are very common *order of magnitude* functions:\n",
    "\n",
    "|f(n)|Name|\n",
    "|------|------|\n",
    "|$1$|Constant|\n",
    "|$logn$|Logarithmic|\n",
    "|$n$|Linear|\n",
    "|$nlogn$|Log Linear|\n",
    "|$n^{2}$|Quadratic|\n",
    "|$n^{3}$|Cubic|\n",
    "|$2^{n}$|Exponential|\n",
    "\n",
    "![order of magnitude](http://interactivepython.org/runestone/static/pythonds/_images/newplot.png)\n",
    "\n",
    "Although we do not see this in the above example, sometimes the performance of an algorithm depends on the *exact values of the data* rather than simply the *size of the problem*. For these kinds of algorithms we need to characterize their performance in terms of **best case**, **worst case**, or **average case** performance. The worst case performance refers to a particular data set where the algorithm performs especially poorly. Whereas a different data set for the exact same algorithm might have extraordinarily good performance. However, in most cases the algorithm performs somewhere in between these two extremes (average case). It is important for a computer scientist to understand these distinctions so they are not misled by one particular case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Anagram Detection Example\n",
    "\n",
    "A good example problem for showing algorithms with different orders of magnitude is the classic anagram detection problem for strings. One string is an anagram of another if the second is simply a rearrangement of the first. For example, 'heart' and 'earth' are anagrams. The strings 'python' and 'typhon' are anagrams as well. For the sake of simplicity, we will assume that the two strings in question are of equal length and that they are made up of symbols from the set of 26 lowercase alphabetic characters. Our goal is to write a boolean function that will take two strings and return whether they are anagrams.\n",
    "\n",
    "See solutions from the book [here](http://interactivepython.org/runestone/static/pythonds/AlgorithmAnalysis/AnAnagramDetectionExample.html).\n",
    "\n",
    "And here is my solution which is $O(n^{2})$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def anagrams(str1, str2):\n",
    "    \n",
    "    are_anagrams = False\n",
    "    list2 = list(str2)\n",
    "\n",
    "    for x in str1:\n",
    "        try:\n",
    "            # list.index() is O(n)\n",
    "            index = list2.index(x)\n",
    "        except ValueError:\n",
    "            break\n",
    "        else:\n",
    "            list2[index] = None\n",
    "    else:\n",
    "        are_anagrams = True\n",
    "\n",
    "    return are_anagrams\n",
    "\n",
    "anagrams('python', 'typhon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance of Python Data Structures\n",
    "\n",
    "Here is the Big-O performance for the operations on Python *lists*.\n",
    "\n",
    "\n",
    "|Operation|\tBig-O Efficiency|\n",
    "|----|----|\n",
    "|index []|\tO(1)|\n",
    "|index assignment|\tO(1)|\n",
    "|append|\tO(1)|\n",
    "|pop()|\tO(1)|\n",
    "|pop(i)|\tO(n)|\n",
    "|insert(i,item)|\tO(n)|\n",
    "|del operator|\tO(n)|\n",
    "|iteration|\tO(n)|\n",
    "|contains (in)|\tO(n)|\n",
    "|get slice [x:y]|\tO(k)|\n",
    "|del slice|\tO(n)|\n",
    "|set slice|\tO(n+k)|\n",
    "|reverse|\tO(n)|\n",
    "|concatenate|\tO(k)|\n",
    "|sort|\tO(n log n)|\n",
    "|multiply|\tO(nk)|\n",
    "\n",
    "Here is the Big-O performance for the operations on Python *dictionaries*:\n",
    "\n",
    "|operation|\tBig-O Efficiency|\n",
    "|------|-----|\n",
    "|copy|\tO(n)|\n",
    "|get item|\tO(1)|\n",
    "|set item|\tO(1)|\n",
    "|delete item|\tO(1)|\n",
    "|contains (in)|\tO(1)|\n",
    "|iteration|\tO(n)|\n",
    "\n",
    "Also see this info in the [docs](https://wiki.python.org/moin/TimeComplexity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
